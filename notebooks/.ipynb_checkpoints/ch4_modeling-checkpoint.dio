<mxGraphModel dx="4086" dy="1750" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="827" pageHeight="1169" background="#ffffff"><root><mxCell id="0"/><mxCell id="1" parent="0"/><mxCell id="64" value="" style="rounded=0;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=#FFCCCC;opacity=60;" parent="1" vertex="1"><mxGeometry x="-104" y="1170" width="524" height="170" as="geometry"/></mxCell><mxCell id="63" value="" style="rounded=0;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#FFCC99;strokeWidth=4;fillColor=#FFE6CC;opacity=60;" parent="1" vertex="1"><mxGeometry x="430" y="1170" width="890" height="1550" as="geometry"/></mxCell><mxCell id="61" value="" style="rounded=0;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#FF33FF;strokeWidth=4;fillColor=#FFCCFF;opacity=60;" parent="1" vertex="1"><mxGeometry x="3520" y="680" width="3120" height="1800" as="geometry"/></mxCell><mxCell id="60" value="" style="rounded=0;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#99CCFF;strokeWidth=4;fillColor=#CCE5FF;opacity=60;" parent="1" vertex="1"><mxGeometry x="1350" y="830" width="2130" height="3570" as="geometry"/></mxCell><mxCell id="2" value="&lt;a href=&quot;https://becominghuman.ai/data-science-simplified-principles-and-process-b06304d63308&quot;&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;Data Science Simplified Part 1: Principles and Process&lt;/u&gt;&lt;/font&gt;&lt;/a&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;#ff3333&quot; size=&quot;1&quot;&gt;&lt;b style=&quot;font-size: 16px&quot;&gt;1. Define Business Problem&lt;/b&gt;&lt;/font&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left&quot;&gt;Albert Einstein once quoted &lt;font color=&quot;#ff3333&quot; style=&quot;font-size: 14px&quot;&gt;“Everything should be made as simple as possible, but not simpler”.&lt;/font&gt; This quote is the crux of defining the business problem.&lt;br&gt;&lt;ul&gt;&lt;li id=&quot;7c51&quot;&gt;The company need grow the customer base by targeting new segments and reducing customer churn.&lt;/li&gt;&lt;/ul&gt;2. Decompose To Machine Learning Tasks&lt;br&gt;The business problem, once defined, needs to be decomposed to machine learning tasks.&lt;br&gt;&lt;ul&gt;&lt;li id=&quot;02a0&quot;&gt;Reduce the customer churn by x %.&lt;/li&gt;&lt;li id=&quot;6f6d&quot;&gt;Identify new customer segments for targeted marketing.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;glass=0;comic=0;shadow=0;" parent="1" vertex="1"><mxGeometry x="-40" y="360" width="880" height="225" as="geometry"/></mxCell><mxCell id="4" value="&lt;font color=&quot;#b266ff&quot; style=&quot;font-size: 30px&quot;&gt;starts here&lt;/font&gt;" style="rounded=1;whiteSpace=wrap;html=1;strokeColor=#CCCCFF;fillColor=#FFCCE6;" parent="1" vertex="1"><mxGeometry x="-1280" y="-360" width="2120" height="160" as="geometry"/></mxCell><mxCell id="5" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;image=https://miro.medium.com/proxy/1*_Iu9oD6j8Z4TEH3KvUqanA.png;" parent="1" vertex="1"><mxGeometry x="-40" y="600" width="891" height="503" as="geometry"/></mxCell><mxCell id="7" value="&lt;a href=&quot;https://blogs.sas.com/content/subconsciousmusings/2020/12/09/machine-learning-algorithm-use/&quot;&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;Which machine learning algorithm should I use?&lt;/u&gt;&lt;/font&gt;&lt;br&gt;&lt;/a&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;h2 style=&quot;text-align: left&quot;&gt;&lt;span&gt;When to use specific algorithms&lt;/span&gt;&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 style=&quot;text-align: left&quot;&gt;&lt;span&gt;PCA, SVD and LDA&lt;/span&gt;&lt;/h3&gt;&lt;p style=&quot;text-align: left&quot;&gt;We generally do not want to feed a large number of features directly into a machine learning algorithm since some features may be irrelevant or the “intrinsic” dimensionality may be smaller than the number of features. Principal component analysis (PCA), singular value decomposition (SVD), and Latent Dirichlet allocation (&lt;em&gt;LDA&lt;/em&gt;) all can be used to perform dimension reduction.&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;b&gt;&lt;font color=&quot;#3399ff&quot;&gt;PCA is an unsupervised clustering method that maps the original data space into a lower-dimensional space while preserving as much information as possible. The PCA basically finds a subspace that most preserve the data variance, with the subspace defined by the dominant eigenvectors of the data’s covariance matrix.&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;glass=0;comic=0;shadow=0;fillColor=#99FFCC;strokeColor=#99FFFF;" parent="1" vertex="1"><mxGeometry x="1360" y="1480" width="880" height="210" as="geometry"/></mxCell><mxCell id="8" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;image=https://blogs.sas.com/content/subconsciousmusings/files/2017/04/machine-learning-cheet-sheet-2.png;" parent="1" vertex="1"><mxGeometry x="1360" y="1720" width="880" height="495" as="geometry"/></mxCell><mxCell id="9" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;image=https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1034305%2Fc062122e95d6a4c6137f6d6e1eb47118%2Froadman.jpeg?generation=1600582178338824&amp;alt=media;" parent="1" vertex="1"><mxGeometry x="-2320" y="-120" width="882" height="1220" as="geometry"/></mxCell><mxCell id="10" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;image=https://assets-global.website-files.com/5debb9b4f88fbc3f702d579e/61ca4fbcc80819e696ba0ee9_Feature-Engineering-Machine-Learning-Diagram.png;" parent="1" vertex="1"><mxGeometry x="1360" y="1080" width="834" height="339" as="geometry"/></mxCell><mxCell id="11" value="&lt;div&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;&lt;a href=&quot;https://www.omnisci.com/technical-glossary/feature-engineering&quot;&gt;Feature Engineering Definitio&lt;/a&gt;n&lt;/u&gt;&lt;/font&gt;&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;glass=0;comic=0;shadow=0;" parent="1" vertex="1"><mxGeometry x="1360" y="840" width="880" height="225" as="geometry"/></mxCell><mxCell id="12" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;image=https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10462-018-09679-z/MediaObjects/10462_2018_9679_Fig1_HTML.png?as=webp;" parent="1" vertex="1"><mxGeometry x="-637" y="600" width="515" height="515" as="geometry"/></mxCell><mxCell id="13" value="&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;&lt;a href=&quot;https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html&quot;&gt;Choosing the right estimator&lt;/a&gt;&lt;/u&gt;&lt;/font&gt;" style="rounded=0;whiteSpace=wrap;html=1;glass=0;comic=0;shadow=0;" parent="1" vertex="1"><mxGeometry x="2280" y="1480" width="1000" height="210" as="geometry"/></mxCell><mxCell id="15" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;image=https://scikit-learn.org/stable/_static/ml_map.png;" parent="1" vertex="1"><mxGeometry x="2280" y="1720" width="995" height="620" as="geometry"/></mxCell><mxCell id="16" value="&lt;div&gt;&lt;a href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z&quot;&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;Machine Learning process&lt;/u&gt;&lt;/font&gt;&lt;br&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;h3 id=&quot;Sec3&quot;&gt;&lt;font style=&quot;font-size: 14px&quot;&gt;Machine Learning process&lt;/font&gt;&lt;/h3&gt;&lt;p style=&quot;text-align: left&quot;&gt;Realization of DM(Data Mining) in many life areas led to the Cross-Industry Standard Process for Data Mining cycle (CRISP-DM&lt;a title=&quot;CRISP-DM (1999) Cross industry standard process for data mining. &amp;lt;br/&amp;gt;                    http://cordis.europa.eu/project/rcn/37679_en.html&amp;lt;br/&amp;gt;                    &amp;lt;br/&amp;gt;                  . Accessed 15 Sept 2018&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR38&quot; id=&quot;ref-link-section-d23436279e652&quot;&gt;1999&lt;/a&gt;), which is now the leading de facto standard for DM applications. The CRISP-DM cycle (Fig.&amp;nbsp;&lt;a href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#Fig1&quot;&gt;1&lt;/a&gt;) consists of six phases:&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;#ff3333&quot;&gt;&lt;b&gt;&lt;span&gt;1.&lt;/span&gt;&lt;i&gt;The business understanding&amp;nbsp;&lt;/i&gt;&lt;span&gt;is usually based on the provided quest formulations and data description.&lt;/span&gt;&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;2.&amp;nbsp;&lt;/span&gt;&lt;i&gt;The data understanding&amp;nbsp;&lt;/i&gt;&lt;span&gt;is based on the provided data and its documentation.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;b&gt;&lt;font color=&quot;#3399ff&quot;&gt;&lt;span&gt;3.&amp;nbsp;&lt;/span&gt;&lt;i&gt;The data preparation&amp;nbsp;&lt;/i&gt;&lt;span&gt;consists of data transformation, exploratory data analysis (EDA), and feature engineering. Each of them can be further divided into smaller sub-steps; e.g., feature engineering consists of feature extraction, feature selection.&lt;/span&gt;&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;b&gt;&lt;font color=&quot;#3399ff&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;font color=&quot;#66b2ff&quot;&gt;&lt;i&gt;Data preparation methods&lt;/i&gt;(including data transformation, EDA, and feature engineering) can be categorized into a number of sub-categories such as dimensionality reduction, sampling (sub-sampling, oversampling), data augmentation, linear methods, statistical testing, feature engineering with feature extraction, feature encoding, feature transformation and feature selection (e.g. mutual information, chi-square&amp;nbsp;&lt;span id=&quot;MathJax-Element-1-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-1&quot;&gt;&lt;span id=&quot;MathJax-Span-2&quot;&gt;&lt;span id=&quot;MathJax-Span-3&quot;&gt;&lt;span id=&quot;MathJax-Span-4&quot;&gt;𝜒&lt;/span&gt;&lt;span id=&quot;MathJax-Span-5&quot;&gt;2&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;statistics, sensitivity analysis) (Bachniak et&amp;nbsp;al.&lt;a title=&quot;Bachniak D, Rauch L, Krol D, Liput J, Slota R, Kitowski J, Pietrzyk M (2017) Sensitivity analysis on HPC systems with Scalarm platform. Concurr Comput 29(9):172–181&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR10&quot; id=&quot;ref-link-section-d23436279e787&quot;&gt;2017&lt;/a&gt;&lt;span style=&quot;letter-spacing: 0px&quot;&gt;). There are also many other algorithms for over-fitting prevention; e.g., regularization, threshold setting, pruning, or dropout.&lt;/span&gt;&lt;/font&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;4.&amp;nbsp;&lt;/span&gt;&lt;span&gt;In&amp;nbsp;&lt;/span&gt;&lt;i&gt;the modeling&amp;nbsp;&lt;/i&gt;&lt;span&gt;phase, various ML algorithms can be applied with different parameter calibrations. The combination between data and parameter variability can lead to extensive repeating of the model train-test-evaluation cycle. If the data is large-scale, the modeling phase will have time-consuming and compute-intensive requirements.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;5.&amp;nbsp;&lt;/span&gt;&lt;i&gt;The evaluation&amp;nbsp;&lt;/i&gt;&lt;span&gt;phase can be performed under various criteria for thorough testing of the ML models in order to choose the best model for the deployment phase.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;6.&amp;nbsp;&lt;/span&gt;&lt;i&gt;The deployment&amp;nbsp;&lt;/i&gt;&lt;span&gt;phase, also called the production phase, involves the usage of a trained ML model to exploit its functionality, as well as the creation of a data pipeline into production.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;font style=&quot;font-size: 14px&quot;&gt;Modeling&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;font style=&quot;font-size: 14px&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Algorithms can be grouped according to the task they intend to solve. Below is one of the widely accepted ML algorithm categorizations (Bishop&amp;nbsp;&lt;a title=&quot;Bishop CM (2006) Pattern recognition and machine learning (information science and statistics). Springer, Berlin&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR15&quot; id=&quot;ref-link-section-d23436279e840&quot;&gt;2006&lt;/a&gt;):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;i&gt;Supervised learning&amp;nbsp;&lt;/i&gt;algorithms are used when each example in the training data consists of a pair&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-2-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-6&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-7&quot;&gt;&lt;span id=&quot;MathJax-Span-8&quot;&gt;(&lt;/span&gt;&lt;span id=&quot;MathJax-Span-9&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-10&quot;&gt;𝑋&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-11&quot;&gt;𝑖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;MathJax-Span-12&quot;&gt;,&lt;/span&gt;&lt;span id=&quot;MathJax-Span-13&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-14&quot;&gt;𝑦&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-15&quot;&gt;𝑖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;MathJax-Span-16&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;, where&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-3-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-17&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-18&quot;&gt;&lt;span id=&quot;MathJax-Span-19&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-20&quot;&gt;𝑋&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-21&quot;&gt;𝑖&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;is the input to be fed into the predictor and&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-4-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-22&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-23&quot;&gt;&lt;span id=&quot;MathJax-Span-24&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-25&quot;&gt;𝑦&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-26&quot;&gt;𝑖&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;is the ground-truth label of the input. The training routine consists of tuning the predictor’s parameters to make its outputs&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-5-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-27&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-28&quot;&gt;&lt;span id=&quot;MathJax-Span-29&quot;&gt;𝑓&lt;/span&gt;&lt;span id=&quot;MathJax-Span-30&quot;&gt;(&lt;/span&gt;&lt;span id=&quot;MathJax-Span-31&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-32&quot;&gt;𝑋&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-33&quot;&gt;𝑖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;MathJax-Span-34&quot;&gt;)&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;as close to&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-6-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-35&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-36&quot;&gt;&lt;span id=&quot;MathJax-Span-37&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-38&quot;&gt;𝑦&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-39&quot;&gt;𝑖&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;as possible. Most of the classification and regression problems fall under this umbrella.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;i&gt;Unsupervised learning&amp;nbsp;&lt;/i&gt;is used to extract information from training data where a ground-truth label&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-7-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-40&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-41&quot;&gt;&lt;span id=&quot;MathJax-Span-42&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-43&quot;&gt;𝑦&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-44&quot;&gt;𝑖 i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;s not available. Among the techniques that would belong to this category is clustering, density estimation, dimensionality reduction, generative adversarial networks or problems where&amp;nbsp;&lt;span&gt;&lt;span id=&quot;MathJax-Element-8-Frame&quot; tabindex=&quot;0&quot;&gt;&lt;nobr&gt;&lt;span id=&quot;MathJax-Span-45&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-46&quot;&gt;&lt;span id=&quot;MathJax-Span-47&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-48&quot;&gt;𝑋&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-49&quot;&gt;𝑖&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;MathJax-Span-50&quot;&gt;=&lt;/span&gt;&lt;span id=&quot;MathJax-Span-51&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-52&quot;&gt;𝑦&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;MathJax-Span-53&quot;&gt;𝑖&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/nobr&gt;&lt;/span&gt;&lt;/span&gt;such as auto-encoders.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;i&gt;Reinforcement learning&amp;nbsp;&lt;/i&gt;is used to design algorithms that select appropriate actions in a given situation in order to maximize reward. In contrast to supervised learning where the predictor is provided with ground-truth labels, here the algorithm must learn by trial and error to find the optimal outputs.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center&quot;&gt;&lt;b&gt;&lt;font style=&quot;font-size: 14px&quot;&gt;Modeling Tuning&lt;/font&gt;&lt;/b&gt;&lt;br&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left&quot;&gt;&lt;p&gt;&lt;i&gt;&lt;br&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Model selection and model performance optimization&amp;nbsp;&lt;/i&gt;contain a large number of approaches such as &lt;font color=&quot;#3399ff&quot;&gt;hyper-parameter tuning, grid search, Bayesian optimization &lt;/font&gt;(Snoek et&amp;nbsp;al.&lt;a title=&quot;Snoek J, Larochelle H, Adams RP (2012) Practical Bayesian optimization of machine learning algorithms. In: Advances in neural information processing systems, pp 2951–2959&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR162&quot; id=&quot;ref-link-section-d23436279e1091&quot;&gt;2012&lt;/a&gt;), &lt;font color=&quot;#3399ff&quot;&gt;local minimum search, and bio-inspired optimization&lt;/font&gt;; e.g., evolutionary algorithms (Triguero et&amp;nbsp;al.&lt;a title=&quot;Triguero I, Gonzalez S, Moyano JM, Garcia S, Alcala-Fdez J, Luengo J, Fernandez A, del Jesus MJ, Sanchez L, Herrera F (2017) Keel 3.0: an open source software for multi-stage analysis in data mining. Int J Comput Intell Syst 10(1):1238–1249&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR184&quot; id=&quot;ref-link-section-d23436279e1094&quot;&gt;2017&lt;/a&gt;; Alcala-Fdez et&amp;nbsp;al.&lt;a title=&quot;Alcala-Fdez J, Fernandez A, Luengo J, Derrac J, Garcia S, Sanchez L, Herrera F (2011) Keel data-mining software tool: data set repository, integration of algorithms and experimental analysis framework. J Mult Valued Logic Soft Comput 17:255–287&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR3&quot; id=&quot;ref-link-section-d23436279e1097&quot;&gt;2011&lt;/a&gt;) and genetic programming (Cano et&amp;nbsp;al.&lt;a title=&quot;Cano A, Luna JM, Zafra A, Ventura S (2015) A classification module for genetic programming algorithms in JCLEC. J Mach Learn Res 16(1):491–494&quot; href=&quot;https://link.springer.com/article/10.1007/s10462-018-09679-z#ref-CR21&quot; id=&quot;ref-link-section-d23436279e1100&quot;&gt;2015&lt;/a&gt;). There are also many methods that can be applied for model evaluation, such as &lt;font color=&quot;#3399ff&quot;&gt;cross-validation, k-fold&lt;/font&gt;, holdout with various metrics such as accuracy (ACC), precision, recall, F1, Matthews correlation coefficient (MCC), receiver operating characteristic (ROC), area under the curve (AUC), mean absolute error (MAE), mean squared error (MSE), and root-mean-square error (RMSE).&lt;/p&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;glass=0;comic=0;shadow=0;" parent="1" vertex="1"><mxGeometry x="-1280" y="-140" width="1200" height="725" as="geometry"/></mxCell><mxCell id="18" value="" style="ellipse;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;fillColor=none;rotation=-30;strokeWidth=4;" parent="1" vertex="1"><mxGeometry x="-122" y="600" width="390" height="240" as="geometry"/></mxCell><mxCell id="19" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://www.ycc.idv.tw/media/mechine_learning_measure/mechine_learning_measure.001.jpeg;" parent="1" vertex="1"><mxGeometry x="3560" y="918" width="1119" height="630" as="geometry"/></mxCell><mxCell id="20" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://www.ycc.idv.tw/media/mechine_learning_measure/mechine_learning_measure.006.jpeg;" parent="1" vertex="1"><mxGeometry x="3560" y="1638" width="1119" height="630" as="geometry"/></mxCell><mxCell id="21" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://www.ycc.idv.tw/media/MachineLearningTechniques/MachineLearningTechniques.017.jpeg;" parent="1" vertex="1"><mxGeometry x="2280" y="2520" width="1189" height="669" as="geometry"/></mxCell><mxCell id="23" value="model performance&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&amp;lt; classification &amp;gt;&lt;/div&gt;" style="rounded=1;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#FF33FF;strokeWidth=4;fillColor=none;" parent="1" vertex="1"><mxGeometry x="3560" y="720" width="1161" height="158" as="geometry"/></mxCell><mxCell id="24" value="model performance&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&amp;lt; regression &amp;gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;p id=&quot;9ea0&quot; style=&quot;text-align: left&quot;&gt;&lt;span&gt;Error Metrics&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id=&quot;92b0&quot; style=&quot;text-align: left&quot;&gt;MSE&lt;/li&gt;&lt;li id=&quot;3d15&quot; style=&quot;text-align: left&quot;&gt;RMSE&lt;/li&gt;&lt;li id=&quot;b9f0&quot; style=&quot;text-align: left&quot;&gt;MAE&lt;/li&gt;&lt;li id=&quot;866b&quot; style=&quot;text-align: left&quot;&gt;MAPE&lt;/li&gt;&lt;/ul&gt;&lt;p id=&quot;39f0&quot; style=&quot;text-align: left&quot;&gt;&lt;span&gt;R² Metrics&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li id=&quot;2269&quot; style=&quot;text-align: left&quot;&gt;R²&lt;/li&gt;&lt;li id=&quot;29bc&quot; style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/li&gt;&lt;li id=&quot;29bc&quot; style=&quot;text-align: left&quot;&gt;Adjusted R²&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;https://towardsdatascience.com/performance-metrics-in-machine-learning-part-2-regression-c60608f3ef6a&quot;&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;Performance Metrics in Machine Learning — Part 2: Regression&lt;/u&gt;&lt;/font&gt;&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide&quot;&gt;&lt;u&gt;&lt;font color=&quot;#b266ff&quot;&gt;Blog&amp;nbsp;&lt;span&gt;»&amp;nbsp;&lt;/span&gt;&lt;span&gt;Model Evaluation&amp;nbsp;»&amp;nbsp;&lt;span&gt;Performance Metrics in Machine Learning [Complete Guide]&lt;/span&gt;&lt;/span&gt;&lt;/font&gt;&lt;/u&gt;&lt;/a&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;font color=&quot;#b266ff&quot; size=&quot;1&quot;&gt;&lt;u&gt;&lt;b style=&quot;font-size: 20px&quot;&gt;Know The Best Evaluation Metrics for Your Regression Model !&lt;/b&gt;&lt;/u&gt;&lt;/font&gt;&lt;br&gt;&lt;/div&gt;" style="rounded=1;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#FF33FF;strokeWidth=4;fillColor=none;" parent="1" vertex="1"><mxGeometry x="4843" y="720" width="1721" height="382" as="geometry"/></mxCell><mxCell id="26" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://i0.wp.com/neptune.ai/wp-content/uploads/Performance-metrics-MSE.jpeg?resize=474%2C328&amp;ssl=1;" parent="1" vertex="1"><mxGeometry x="-3120" y="882" width="474" height="328" as="geometry"/></mxCell><mxCell id="27" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://i0.wp.com/neptune.ai/wp-content/uploads/Performance-metrics-MAE.png?resize=474%2C328&amp;ssl=1;" parent="1" vertex="1"><mxGeometry x="-3120" y="1232" width="474" height="328" as="geometry"/></mxCell><mxCell id="28" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://miro.medium.com/max/341/0*omsdYpfRvm3ALVaO;" parent="1" vertex="1"><mxGeometry x="4943" y="1320" width="341" height="93" as="geometry"/></mxCell><mxCell id="29" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://lh6.googleusercontent.com/gbSihak-qx9VaNa-ibUqxaIM6mD9nmfwI7wwxK_tRyOfUUGJ_XnH6jU_vcDqD9IgI1disL-cTIELJx5skJZ2uIX6oSC9rG2M8hKoabc4fIoBzJdNg3NkT91GBqH9yabg5sKSf4-J;" parent="1" vertex="1"><mxGeometry x="5603" y="1682" width="313" height="97" as="geometry"/></mxCell><mxCell id="30" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://lh5.googleusercontent.com/pxb5gFdX2WYgW5dAvofM3bGUpJumpr_ATYdTScT3oXB-fXr-wAZ4QTOEjNaWpDtVPyU_Iyv62uJ3HlzAcT6dVj9x5ZgZ246oCgD5zVVOW65EQ8XUnESmVVHRLt7sc5szK4pIXxC_;" parent="1" vertex="1"><mxGeometry x="5603" y="1300" width="382" height="113" as="geometry"/></mxCell><mxCell id="31" value="&lt;p&gt;It addresses a few downsides in MSE.&lt;/p&gt;&lt;p&gt;Few key points related to RMSE:&lt;/p&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;It retains the differentiable property of MSE.&lt;/li&gt;&lt;li&gt;It handles the penalization of smaller errors done by MSE by square rooting it.&lt;/li&gt;&lt;li&gt;Error interpretation can be done smoothly, since the scale is now the same as the random variable.&lt;/li&gt;&lt;li&gt;Since scale factors are essentially normalized, it’s less prone to struggle in the case of outliers.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;" parent="1" vertex="1"><mxGeometry x="5603" y="1434" width="580" height="110" as="geometry"/></mxCell><mxCell id="32" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://lh3.googleusercontent.com/-JBio3Q_1FiI/YB2oQKEmRBI/AAAAAAAAAkM/c8KJ3wPwtMEd3Ik0nYMMdmr_pRqMF6MlQCLcBGAsYHQ/w550-h177/image.png;" parent="1" vertex="1"><mxGeometry x="4883" y="1138" width="442" height="177" as="geometry"/></mxCell><mxCell id="33" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://editor.analyticsvidhya.com/uploads/22091R2%20Squared%20Formula.png;" parent="1" vertex="1"><mxGeometry x="4965" y="1922" width="360" height="250" as="geometry"/></mxCell><mxCell id="34" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://lh3.googleusercontent.com/-6T1LxrK1by8/YB6D5hjSCjI/AAAAAAAAAlk/gCmLpEJMJ3MpwO6r-sI7GQzuOQP2I1B3QCLcBGAsYHQ/w332-h179/image.png;" parent="1" vertex="1"><mxGeometry x="5603" y="1960" width="319" height="179" as="geometry"/></mxCell><mxCell id="35" value="&lt;p&gt;The disadvantage of the R2 score is while adding new features in data the R2 score starts increasing or remains constant but it never decreases &lt;br&gt;because It assumes that while adding more data variance of data increases.&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;&lt;font color=&quot;#3399ff&quot;&gt;But the problem is when we add an irrelevant feature in the dataset then at that time R2 sometimes starts increasing which is incorrect.&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;And if we add a relevant feature then the R2 score will increase and 1-R2 will decrease heavily and the denominator will also decrease so the complete term decreases, &lt;br&gt;and on subtracting from one the score increases.&lt;/span&gt;&lt;br&gt;&lt;/p&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;" parent="1" vertex="1"><mxGeometry x="5603" y="2155" width="910" height="100" as="geometry"/></mxCell><mxCell id="38" value="" style="group" parent="1" vertex="1" connectable="0"><mxGeometry x="5363" y="1332" width="200" height="24" as="geometry"/></mxCell><mxCell id="36" value="" style="endArrow=classic;html=1;strokeWidth=3;" parent="38" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint y="24" as="sourcePoint"/><mxPoint x="200" y="24" as="targetPoint"/></mxGeometry></mxCell><mxCell id="37" value="&lt;font style=&quot;font-size: 14px&quot;&gt;adjust and refine&lt;/font&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;" parent="38" vertex="1"><mxGeometry x="50" width="120" height="20" as="geometry"/></mxCell><mxCell id="39" value="" style="group" parent="1" vertex="1" connectable="0"><mxGeometry x="5363" y="2023" width="200" height="24" as="geometry"/></mxCell><mxCell id="40" value="" style="endArrow=classic;html=1;strokeWidth=3;" parent="39" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint y="24" as="sourcePoint"/><mxPoint x="200" y="24" as="targetPoint"/></mxGeometry></mxCell><mxCell id="41" value="&lt;font style=&quot;font-size: 14px&quot;&gt;adjust and refine&lt;/font&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;" parent="39" vertex="1"><mxGeometry x="50" width="120" height="20" as="geometry"/></mxCell><mxCell id="42" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://www.allaboutcircuits.com/uploads/articles/Machine_Learning_Flowchart_1.jpg;" parent="1" vertex="1"><mxGeometry x="-1240" y="640" width="555" height="379" as="geometry"/></mxCell><mxCell id="43" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://miro.medium.com/max/1400/1*qY8oFllNGkKA3AYITC_Gbw.png;" parent="1" vertex="1"><mxGeometry x="440" y="1800" width="813" height="360" as="geometry"/></mxCell><mxCell id="44" value="&lt;font style=&quot;font-size: 16px&quot;&gt;&lt;font color=&quot;#3399ff&quot;&gt;EDA (Exploratory Data Analysis)&lt;/font&gt; is a technique of preforming initial analysis on the raw data sets so as to&amp;nbsp;&lt;/font&gt;&lt;div&gt;&lt;span&gt;&lt;font style=&quot;font-size: 16px&quot;&gt;get insights from the data,&amp;nbsp;&lt;/font&gt;&lt;/span&gt;&lt;div&gt;&lt;span&gt;&lt;font style=&quot;font-size: 16px&quot;&gt;explore different patterns or anomalies,&amp;nbsp;&lt;/font&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;font style=&quot;font-size: 16px&quot;&gt;to test hypothesis&amp;nbsp;&lt;/font&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;font style=&quot;font-size: 16px&quot;&gt;and &lt;font color=&quot;#3399ff&quot;&gt;finally make some assumption based on statistical models and graphical representation&lt;/font&gt;.&lt;/font&gt;&lt;/div&gt;&lt;/div&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;rounded=0;" parent="1" vertex="1"><mxGeometry x="440" y="2160" width="760" height="80" as="geometry"/></mxCell><mxCell id="45" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://www.researchgate.net/profile/Cristina-Sousa-2/publication/342282008/figure/fig2/AS:903839578353665@1592503556728/Exploratory-Data-Analysis-EDA-steps.png;" parent="1" vertex="1"><mxGeometry x="440" y="2321" width="773" height="360" as="geometry"/></mxCell><mxCell id="46" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://editor.analyticsvidhya.com/uploads/24537Zoom-EDA.png;" parent="1" vertex="1"><mxGeometry x="440" y="1441" width="691" height="345" as="geometry"/></mxCell><mxCell id="47" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF3333;strokeWidth=4;fillColor=none;image=https://editor.analyticsvidhya.com/uploads/39379DS-flow.png;" parent="1" vertex="1"><mxGeometry x="440" y="1240" width="705" height="202" as="geometry"/></mxCell><mxCell id="48" value="&lt;div&gt;&amp;lt; &lt;font color=&quot;#ff3333&quot;&gt;Define Business Problem&lt;/font&gt; &amp;gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;consider all kinds of things, including:&lt;/div&gt;&lt;div&gt;the limitation(your knowledge, your limited resource, what are you able to do in this moment),&amp;nbsp;&lt;/div&gt;&lt;div&gt;the most important question you are eager to know,&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;define it to be &lt;font color=&quot;#ff3333&quot;&gt;a specific question, a specific goal&lt;/font&gt;, i.e., &lt;font color=&quot;#ff3333&quot;&gt;define your destination&lt;/font&gt;&lt;div&gt;&lt;font color=&quot;#ff3333&quot;&gt;and then you can think backward and find where you can start to get there&lt;/font&gt;&lt;/div&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;" parent="1" vertex="1"><mxGeometry x="-89" y="1190" width="510" height="110" as="geometry"/></mxCell><mxCell id="49" value="" style="shape=flexArrow;endArrow=classic;html=1;fillColor=none;strokeWidth=3;strokeColor=#FF3333;" parent="1" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint x="-60" y="861" as="sourcePoint"/><mxPoint x="-60" y="1150" as="targetPoint"/></mxGeometry></mxCell><mxCell id="50" value="" style="ellipse;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FFCC99;fillColor=none;rotation=0;strokeWidth=4;" parent="1" vertex="1"><mxGeometry x="400" y="760" width="160" height="140" as="geometry"/></mxCell><mxCell id="51" value="" style="shape=flexArrow;endArrow=classic;html=1;fillColor=none;strokeWidth=3;strokeColor=#FFCC99;" parent="1" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint x="480" y="911" as="sourcePoint"/><mxPoint x="480" y="1160" as="targetPoint"/></mxGeometry></mxCell><mxCell id="52" value="" style="ellipse;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#99CCFF;fillColor=none;rotation=0;strokeWidth=4;" parent="1" vertex="1"><mxGeometry x="560" y="770" width="130" height="120" as="geometry"/></mxCell><mxCell id="53" value="" style="shape=flexArrow;endArrow=classic;html=1;fillColor=none;strokeWidth=3;strokeColor=#99CCFF;exitX=1;exitY=1;" parent="1" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint x="650" y="890" as="sourcePoint"/><mxPoint x="1330" y="890" as="targetPoint"/></mxGeometry></mxCell><mxCell id="56" value="" style="ellipse;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#FF33FF;fillColor=none;rotation=0;strokeWidth=4;" parent="1" vertex="1"><mxGeometry x="710" y="772" width="120" height="110" as="geometry"/></mxCell><mxCell id="57" value="" style="shape=flexArrow;endArrow=classic;html=1;fillColor=none;strokeWidth=3;strokeColor=#FF33FF;exitX=1;exitY=1;" parent="1" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint x="810" y="780" as="sourcePoint"/><mxPoint x="3510" y="780" as="targetPoint"/></mxGeometry></mxCell><mxCell id="65" value="&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2021/04/rapid-fire-eda-process-using-python-for-ml-implementation/&quot;&gt;&lt;font color=&quot;#cc99ff&quot;&gt;&lt;u&gt;useful code to do EDA -&amp;nbsp;Rapid-Fire EDA process using Python for ML Implementation&lt;/u&gt;&lt;/font&gt;&lt;/a&gt;" style="rounded=0;whiteSpace=wrap;html=1;shadow=0;glass=0;comic=0;strokeColor=#000000;strokeWidth=1;fillColor=none;" parent="1" vertex="1"><mxGeometry x="440" y="1180" width="720" height="40" as="geometry"/></mxCell><mxCell id="66" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#000000;strokeWidth=2;fillColor=none;image=https://miro.medium.com/max/1200/1*PzzcJA-cwXQ8hwlpM4DwbA@2x.jpeg;" parent="1" vertex="1"><mxGeometry x="120" y="-160" width="540" height="511" as="geometry"/></mxCell><mxCell id="67" value="&lt;font style=&quot;font-size: 16px&quot;&gt;someone's career path&lt;/font&gt;&lt;div style=&quot;font-size: 16px&quot;&gt;&lt;font style=&quot;font-size: 16px&quot; color=&quot;#ff0000&quot;&gt;it's absolutely not an easy path !!&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;font style=&quot;font-size: 20px&quot;&gt;e.g.&amp;nbsp;&lt;/font&gt;&lt;a href=&quot;https://hastie.su.domains/ElemStatLearn/&quot; style=&quot;font-size: 30px&quot;&gt;&lt;u&gt;The Elements of Statistical Learning (ESL II, 2nd edition&lt;/u&gt;&lt;/a&gt;&lt;span style=&quot;font-size: 30px&quot;&gt;)&lt;/span&gt;&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;font color=&quot;#b266ff&quot; style=&quot;font-size: 16px&quot;&gt;it is one of the bibles of ML, from the statistical aspect&lt;/font&gt;&lt;/div&gt;" style="rounded=1;whiteSpace=wrap;html=1;strokeColor=#CCCCFF;fillColor=#FFCCE6;" parent="1" vertex="1"><mxGeometry x="-2318" y="-360" width="880" height="160" as="geometry"/></mxCell><mxCell id="68" value="&lt;div style=&quot;text-align: center&quot;&gt;&lt;a href=&quot;https://blogs.sas.com/content/subconsciousmusings/2020/12/09/machine-learning-algorithm-use/&quot; style=&quot;letter-spacing: 0px&quot;&gt;&lt;font color=&quot;#b266ff&quot;&gt;&lt;u&gt;Ensemble Methods&lt;/u&gt;&lt;/font&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;p style=&quot;text-align: left&quot;&gt;- purpose&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&amp;gt; 集成就是使用不同方式，(1)多使用幾次不同的抽出放回的資料(data aspect)，(2)或給多個/多種不同分類器(model aspect)，來截長補短，綜合預測&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;- data ensemble&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&amp;gt; bagging, boosting&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;- model ensemble&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&amp;gt; blending, stacking&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&lt;br&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left&quot;&gt;&amp;gt; note. blending 使用的注意事項: 個別單模效果都很好，並且模型差異大．單模要好尤其重要，如果單模效果差異太大，blending 能提升的效果就有限．&lt;/p&gt;&lt;/div&gt;" style="rounded=0;whiteSpace=wrap;html=1;glass=0;comic=0;shadow=0;fillColor=#99FFCC;strokeColor=#99FFFF;" parent="1" vertex="1"><mxGeometry x="1360" y="3210" width="880" height="240" as="geometry"/></mxCell><mxCell id="69" value="" style="shape=image;imageAspect=0;aspect=fixed;verticalLabelPosition=bottom;verticalAlign=top;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#000000;strokeWidth=2;fillColor=none;image=https://prwatech.in/blog/wp-content/uploads/2020/02/ensemright.png;" parent="1" vertex="1"><mxGeometry x="1360" y="3470" width="474" height="335" as="geometry"/></mxCell><mxCell id="70" value="" style="endArrow=none;html=1;strokeColor=#FF00FF;strokeWidth=4;" parent="1" edge="1"><mxGeometry width="50" height="50" relative="1" as="geometry"><mxPoint x="4780" y="2520" as="sourcePoint"/><mxPoint x="4780" y="720" as="targetPoint"/></mxGeometry></mxCell><mxCell id="71" value="&lt;div&gt;&lt;span style=&quot;letter-spacing: 0px&quot;&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;ROC AUC curve -&amp;nbsp;&lt;/font&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;y-axis: TPR(True Positive Rate = TP / (TP+FN) = True Positive / Actual Positive = Predict Positive and correct / Actual Positive)&lt;span&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;/span&gt;&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;letter-spacing: 0px&quot;&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;x-axis: FPR(False Positive Rate = FP / (FP + TN) = False Positive / Actual Negative = Predict Positive and wrong / Actual Negative)&lt;/font&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;letter-spacing: 0px&quot;&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;--&amp;gt; numerator(分子) of both TRP and FPR: try to 'Predict Positive', BUT, predict correctly or predict wrongly&lt;/font&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;letter-spacing: 0px&quot;&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;font style=&quot;font-size: 12px&quot;&gt;&lt;span style=&quot;letter-spacing: 0px&quot;&gt;繪製原理很直覺，&lt;/span&gt;&lt;br&gt;&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;font&gt;若實際值為1(真), i.e., if actual label=1, means it is Actual Positive，&lt;/font&gt;&lt;/div&gt;&lt;div&gt;&lt;font&gt;表示真陽(預測超過門檻)，故Y軸加1格&amp;nbsp;&lt;/font&gt;&lt;span&gt;(Predict Positive 'correctly' 所以Y軸 + 1)&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;font&gt;&lt;span&gt;&lt;font&gt;反之，為假陽(預測超過門檻，但實際為假)，故X軸&lt;/font&gt;&lt;/span&gt;&lt;span&gt;加1格&amp;nbsp;&lt;/span&gt;&lt;/font&gt;&lt;span&gt;(Predict Positive 'wrongly' 所以X軸 + 1)&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;strokeColor=#000000;" vertex="1" parent="1"><mxGeometry x="4030" y="2280" width="710" height="160" as="geometry"/></mxCell><mxCell id="72" value="&lt;ul&gt;&lt;li&gt;&lt;span&gt;Power&lt;/span&gt;(1-β): &lt;br&gt;the probability correctly rejecting the null hypothesis (when the null hypothesis isn’t true).&lt;/li&gt;&lt;/ul&gt;" style="text;html=1;resizable=0;points=[];autosize=1;align=left;verticalAlign=top;spacingTop=-4;" vertex="1" parent="1"><mxGeometry x="3510" y="2280" width="530" height="50" as="geometry"/></mxCell></root></mxGraphModel>